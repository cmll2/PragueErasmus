{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a0987d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Camille Louis HascoÃ«t\"      # insert your full name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0daf7cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02979c89-9705-4c1d-a18b-a3c205e0b900",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e56d12afdf74271a9a0f99197e52f004",
     "grade": false,
     "grade_id": "cell-89cfbc72cc7f9269",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.testing import assert_approx_equal, assert_allclose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add2de8-a4da-4515-b252-b374049619c8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5765f31eb64db9ecbcc00209e23630cc",
     "grade": false,
     "grade_id": "cell-0b138784186196fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2: Multilayered Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdddbf1-6a8c-4463-bb72-eb177176e29b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07b33b1186dff16973d810ea76ab6d22",
     "grade": false,
     "grade_id": "cell-5fce3c3d1da77c16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1: Weight initialization for a single neuron (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41be502-ba30-44b2-a5a3-8853dde1d551",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c288da46bf9e1c2a90b38e63940a8b25",
     "grade": false,
     "grade_id": "cell-29390ef632b1531a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let us have a simple neural network with $N$ inputs and a single output neuron **without bias**. The neuron uses the sigmoidal transfer function\n",
    "        $$\\hspace{5em} f(x) = \\frac{1}{1+e^{-x}}\\ .$$\n",
    "Its potential is\n",
    "        $$\\hspace{5em} \\xi = \\sum_{i=1}^{N} w_i x_i\\,, $$\n",
    "where $w_i$ and $x_i$ are the weight and value of $i$-th input, respectively, for $i=1, \\dots, N$.\n",
    "\n",
    "For fast learning of this neuron, the absolute value of the potential should not be too high. The input attributes are real values without restriction, but we know they have a normal probability distribution with mean value $\\mu = 0$ and standard deviation $\\sigma, \\;\\sigma > 0$. We will initialize the neuron weights with values from the uniform distribution on an interval $\\langle -a,a \\rangle$. \n",
    "\n",
    "How should we set the value $a$ with respect to $\\sigma$ if we require that the potential on the neuron should have zero expected value and standard deviation $A = 1$?\n",
    "\n",
    "*Hint: A similar problem when the input values were from a uniform distribution was solved within the lecture on multilayered neural networks.*\n",
    "\n",
    "#### What to submit:\n",
    "A complete derivation of the proper value of the variable $a$ with respect to $\\sigma$ and $A$. The derivation can be written by hand and submitted as a scanned picture (or an image captured by, e.g., a mobile phone) in a separate file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2af880d-49fa-4d8c-bcef-3c0089990edb",
   "metadata": {},
   "source": [
    "# Task 2: Manual design of a neural network for computing a function (3 points)\n",
    "\n",
    "Suggest weights of a multilayered neural network computing the function $f(x_1,x_2) = 2 - x_1 + x_2$, where $x_1, x_2$ are input bits (of value 0 or 1 each). The network's neurons should use the sigmoidal transfer function with slope 1, the weights and biases should be **\"small\" integers** (with absolute value at most 20). In contrast to Task 1, the neurons **have biases**. The topology of the network must be 2-2-2. That is:\n",
    "* two input neurons -- inputs are bits (with value 0 or 1),\n",
    "* two neurons in a single hidden layer, and\n",
    "* two neurons in the output layer.\n",
    "\n",
    "Outputs of the network (at the output layer only!) will be interpreted as two-bit binary numbers in the following way:\n",
    "* output greater or equal to 0.5 will be considered as logical 1,\n",
    "* output less than 0.5 will be considered as logical 0.\n",
    "\n",
    "#### What to submit \n",
    "Extended weight matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cddb0b42-535b-49f8-9a50-448b937cd31d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60db950f9aee71ea8a04dcf514ef596b",
     "grade": false,
     "grade_id": "cell-1da52d4651dc0bf0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# The extended weight matrix between the input and hidden layer\n",
    "w_i_hb = np.array([[20, -20], [20,20], [20,20]])  #np.array with dimension 3 x 2\n",
    "\n",
    "# The extended weight matrix between the hidden and output layer\n",
    "w_h_ob = np.array([[20,20],[20,-20],[20,0]])  #np.array with dimension 3 x 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77c9b7-7a5f-4d96-8638-b9dd8a6ccdc4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6c32d7c252f171d278b26856d81c3b7",
     "grade": false,
     "grade_id": "cell-63b3b1e76979c803",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Hint: The weights can be proposed \"manually\" by assuming that the hidden neurons compute suitable logical functions. However, the output of the hidden neurons will not be rounded!*\n",
    "\n",
    "Your proposed weights will be tested below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca86bd89-ac4a-4d37-9d6a-07a6940f9523",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3818bdf06a89dec840349ddc6e94971c",
     "grade": true,
     "grade_id": "cell-f7cbf1042d0b1cd2",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n",
      "[1. 0.]\n"
     ]
    }
   ],
   "source": [
    "def sigm(x, slope=1.0):\n",
    "    return 1/(1+np.exp(-slope * x))\n",
    "\n",
    "def sigm_deriv(x, slope=1.0):\n",
    "    #sigm_x = sigm(x, slope)\n",
    "    return slope * x * (1 - x)\n",
    "\n",
    "assert(w_i_hb.dtype == int)\n",
    "assert(w_h_ob.dtype == int)\n",
    "\n",
    "extended_input = np.array([0,0,1])\n",
    "print(sigm(extended_input @ w_i_hb))\n",
    "print(np.round(sigm(np.r_[sigm(extended_input @ w_i_hb),1] @ w_h_ob)))\n",
    "\n",
    "# for input (0,0), the output should be (1,0)\n",
    "assert (np.round(sigm(np.r_[sigm(extended_input @ w_i_hb),1] @ w_h_ob)) == np.array([1,0])).all()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d62ba7-5dae-4038-87cc-75213922bcd6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3cb87321fe3e54639775ff0e499df3a0",
     "grade": false,
     "grade_id": "cell-c80f5f6d12da1106",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 3: Backpropagation algorithm (3 points)\n",
    "We have a multilayered neural network with the topology 2-4-2, i.e., it has two input neurons, one hidden layer containing four neurons, and two output neurons. All neurons use the sigmoidal transfer function with the slope $\\lambda =2.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92ea75fc-8711-439c-bb60-51f6fc39f3a3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e9fdcb0ed45504747308db8f27feb5f7",
     "grade": false,
     "grade_id": "cell-5855151f2c774fff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "lam = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f02ae5a-e6ac-46fd-9aef-a2ed97deb3bc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "32f3713d8fb861d48f6fe26b3ffb01e8",
     "grade": false,
     "grade_id": "cell-80b9c8442d382cfa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The extended weight matrix of weights between the input and the hidden layer is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e633946d-8c62-47b8-920a-42ce6645a61f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eaf826ac397e0e63977e70b601d911e3",
     "grade": false,
     "grade_id": "cell-078aadd5e5dd0466",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "w_i_hb = np.array([[ 1.1, -2.2,  1.0,  0.5],\n",
    "                   [ 0.5,  0.9,  2.0, -1.0],\n",
    "                   [ 0.0, -0.4, -1.0, -0.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4a705d-430e-4db9-a871-d7cd311484f9",
   "metadata": {},
   "source": [
    "and the extended weight matrix between the hidden and the output layer is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "11462f9b-e6c9-45de-b88e-33ae8cf6fe90",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1528b33715613708e7b024f0048a741",
     "grade": false,
     "grade_id": "cell-b9fce90cc84d35fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "w_h_ob = np.array([[ 2.0,  0.9],\n",
    "                   [-1.0,  1.1],\n",
    "                   [-2.2, -0.8],\n",
    "                   [ 1.5,  0.0],\n",
    "                   [ 0.5, -0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9d65a34-534f-44bd-b376-d61ab7cc7643",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbe56162f286b82eb617590648f6254c",
     "grade": false,
     "grade_id": "cell-4f0fbffb2a4fbe8f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "p = np.array([-1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d756972-e01c-4f2e-8435-30654342f448",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ef1e1b3eeb966ff793d9940a0b318309",
     "grade": false,
     "grade_id": "cell-8427c840f4a9fc1d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "with the desired output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fec2fa3-837b-4bb1-8ebc-8f3a37600db6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be94b499b1779923ab50d40f3378e2e7",
     "grade": false,
     "grade_id": "cell-9b83a3a3728f4376",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "d = np.array([0.2, 0.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556061a-0ac2-4fb9-8b99-d6eccf55611f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90a3410418f6d811084c063d258f2895",
     "grade": false,
     "grade_id": "cell-8b49e4ffc8c5caf5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "and the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad319b0c-2110-4835-8635-185c1fe16389",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "886a148ca5c92d214d442a8c5feb5993",
     "grade": false,
     "grade_id": "cell-e33bc2a96c6b84ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "alpha = 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38eeb169-4273-4dc2-82a6-7ec7c2c1ac7f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "94b3d4abd79829c0e2820338e531f319",
     "grade": false,
     "grade_id": "cell-4f9278df03e4a530",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "To solve this assignment, you must **not use any library for learning neural networks**!\n",
    "\n",
    "#### What to submit\n",
    "A Python code in the cell below computing the new extended weight matrices `w_i_hb1` and `w_h_ob1` after one iteration of the backpropagation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9aeccc83-b776-41ba-908a-e2e80babe7d1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c84859060b4a22dce299dbe6ebac274",
     "grade": false,
     "grade_id": "cell-6aec548806cf1fcc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def bp_iteration(p, d, w_i_hb, w_h_ob, alpha, lam):\n",
    "    w_h_ob, w_i_hb = w_h_ob.astype(np.float64), w_i_hb.astype(np.float64)\n",
    "    lam, alpha = float(lam), float(alpha)\n",
    "    extended_input = np.append(p, 1)  # Adding bias term to input\n",
    "    hidden_input = extended_input @ w_i_hb\n",
    "    hidden_output = sigm(hidden_input, lam)\n",
    "    hidden_output_with_bias = np.append(hidden_output, 1)  # Adding bias term to hidden layer output\n",
    "\n",
    "    final_input = hidden_output_with_bias @ w_h_ob\n",
    "    final_output = sigm(final_input, lam)\n",
    "\n",
    "    # Backward pass\n",
    "    output_error = d - final_output\n",
    "    output_delta = output_error * sigm_deriv(final_output, lam)\n",
    "\n",
    "    hidden_error = output_delta @ w_h_ob[:-1].T  # Removing bias weights from calculation\n",
    "    hidden_delta = hidden_error * sigm_deriv(hidden_output, lam)\n",
    "\n",
    "    # Weight updates\n",
    "    w_h_ob += alpha * np.outer(hidden_output_with_bias, output_delta)\n",
    "    w_i_hb += alpha * np.outer(extended_input, hidden_delta)\n",
    "\n",
    "    return w_i_hb, w_h_ob\n",
    "\n",
    "w_i_hb1, w_h_ob1 = bp_iteration(p, d, w_i_hb, w_h_ob, alpha, lam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5a85f1-fa9e-4622-9c47-0d54871ed59f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6828ca605f71e64ab418dd28f521decf",
     "grade": false,
     "grade_id": "cell-268be7fe693325c4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the cell below, your results will be checked using several hidden tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecd183fd-4375-41cc-baf5-daa60e4c1531",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35d0cd62104ed13eabf52973514f01c4",
     "grade": true,
     "grade_id": "cell-37d7f04203e6984f",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ouput before training: [0.09720079 0.69141942]\n",
      "Ouput after training: [0.07185376 0.44076691]\n",
      "w_i_hb1:\n",
      " [[ 1.14047168 -2.1979209   0.95515682  0.49902726]\n",
      " [ 0.45952832  0.8979209   2.04484318 -0.99902726]\n",
      " [-0.04047168 -0.4020791  -0.95515682 -0.69902726]]\n",
      "w_h_ob1:\n",
      " [[ 2.00626436  0.85682281]\n",
      " [-0.97305893  0.91430817]\n",
      " [-2.18646862 -0.89326526]\n",
      " [ 1.50032823 -0.00226232]\n",
      " [ 0.52706275 -0.68653052]]\n"
     ]
    }
   ],
   "source": [
    "y_o = sigm(np.r_[sigm(np.r_[p,1] @ w_i_hb, lam),1] @ w_h_ob, lam)\n",
    "print(\"Ouput before training:\", y_o)\n",
    "y_o1 = sigm(np.r_[sigm(np.r_[p,1] @ w_i_hb1, lam),1] @ w_h_ob1, lam)\n",
    "print(\"Ouput after training:\", y_o1)\n",
    "print(\"w_i_hb1:\\n\", w_i_hb1)\n",
    "print(\"w_h_ob1:\\n\", w_h_ob1)\n",
    "\n",
    "assert_allclose(y_o, [0.09720079, 0.69141942])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daeee56-9d91-44a6-9f6d-01fe1629e4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
