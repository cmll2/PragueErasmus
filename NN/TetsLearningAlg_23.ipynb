{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"5863ceee3c964d6e8abe5dbb682db928","deepnote_cell_type":"markdown"},"source":"Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n\nMake sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:","block_group":"e33023e7494c4c748029fa1f83333024"},{"cell_type":"code","metadata":{"cell_id":"d91a80e4097b4132a81a7570c4953067","deepnote_cell_type":"code"},"source":"NAME = \"\"\nCOLLABORATORS = \"\"","block_group":"32d1aeba2a854761a840ad4cd4b38444","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"60b93af71daa4b2cb334b3fd3e2917b4","deepnote_cell_type":"markdown"},"source":"---","block_group":"358fce0109224ccc9602068888e1dc2f"},{"cell_type":"code","metadata":{"cell_id":"0252e4936d064c48aeb3453892bd1229","deepnote_cell_type":"code"},"source":"import numpy as np\nimport scipy\nimport sklearn\nimport matplotlib.pyplot as plt\n","block_group":"10085003966b45679cf63b1b3e3e231b","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"ae48c14c5ad14023983aaec12fb75df6","deepnote_cell_type":"markdown"},"source":"# Testing Machine Learning Algorithms\n\n*Based on Tom Mitchell: Machine Learning, McGraw-Hill Science/Engineering/Math, 1997; Chapter 5, pages 128-153; [full text from the author](http://www.cs.cmu.edu/~tom/files/MachineLearningTomMitchell.pdf)*\n\n**Task:** Let $X$ be a set, e.g., the set of all $d$-dimensional vectors\nwith entries from the interval $\\langle 0,1\\rangle$. Let\n$f: X \\to \\{0,1\\}$ be a target function. The goal of a learning\nalgorithm is to identify a function $h: X \\to \\{0,1\\}$, called\nhypothesis, from some class of functions $\\mathcal{H}$ such that the\nfunction $h$ is a good approximation of the target function $f$. The\nonly information the algorithm can use is a sample $S\\subset X$ called\ntraining set together with the correct value $f(x)$ for each $x \\in S$.\nThe sample $S$ is a set of $n$ elements from $X$ randomly selected\naccording to some probabilistic distribution $D$.\n\nWhen the learning algorithm selects some function $h$, we can easily\nmeasure how well $h$ approximates $f$ on the training set by counting\nthe number of elements from $S$ for which both functions $f$ and $h$\nhave the same value. Then, the error of  hypothesis $h$ on the\ntraining set is\n$${\\sf Error}_S(h)=\\frac{1}{n} \\sum_{x \\in S} \\delta(f(x),h(x)) \\enspace,$$\nwhere $n$ is the size of $S$ and $\\delta$ is the classification error\nfunction $$\\delta(\\alpha,\\beta) =\n\\begin{cases}\n    1 & \\text{for $\\alpha\\not= \\beta$}\\\\\n    0 & \\text{for $\\alpha = \\beta$}\n\\end{cases}$$ Hence, $${\\sf Error}_S(h)=\\frac{r}{n}\\enspace,$$ where $r$\nis the number of elements from $S$, which were incorrectly classified by\n$h$.\n\n**Problems:**\n\n1.  How can we estimate the accuracy of $h$ on *any* sample taken from $X$\n    according to the same probability distribution $D$?\n\n2.  How good is this estimator - what is the probable error of this\n    estimator?\n\nWe want to know the error rate of the hypothesis $h$ on the whole set\n$X$, i.e., the probability that an element $x \\in X$ selected according\nto the probability distribution $D$ is classified incorrectly:\n$${\\sf Error}_D = Pr_{x \\in D} [f(x) \\not= h(x)] \\enspace.$$ Such an error\nis called *true error*. It has a binomial distribution. An estimator of\nthe error can be computed as the number of incorrectly classified\nsamples divided by the number of samples. However, this estimator must\nbe computed on a sample that is independent of the training set $S$!\nHence:\n\n> **An estimator of the error of a learning algorithm must be computed\n> on a test set $T$ ($\\subset X$) independent (disjunctive) of $S$.**\n\nThe **maximum likelihood estimate** of the true error rate of the learning\nalgorithm can be computed from the number of errors $r_T$ on a test set\n$T$ of size $n_T=|T|$ as: $${\\sf Error}_T(h)=\\frac{r_T}{n_T}\\enspace.$$\nThen, the expected number of errors on $n_T$ samples is $r_T$. Variance\nof the number of errors is according to the binomial distribution:\n$${\\sf Var'}_T = n_T \\cdot \\frac{r_T}{n_T} \\cdot \\left(1 - \\frac{r_T}{n_T}\\right) = n_T \\cdot {\\sf Error}_T(h)\\cdot (1 - {\\sf Error}_T(h))\\enspace.$$\nAlso, the standard deviation of the expected number of errors is:\n$$\\sigma'_T = \\sqrt{ {n_T \\cdot \\sf Error}_T(h)\\cdot (1 - {\\sf\nError}_T(h))}\\enspace.$$ Hence the standard deviation of the estimator of\n**the error rate** of hypothesis $h$ on the test set $T$ is\n$$\\sigma_T = \\frac{\\sigma'_T}{n_T} =  \\sqrt{\\frac{{\\sf Error}_T(h)\\cdot (1 - {\\sf Error}_T(h))}{n_T}}\\enspace.$$","block_group":"5d6c3291852a4a6cae58bb9408f54a32"},{"cell_type":"code","metadata":{"cell_id":"967379562fff41c29059af8e1e5be835","deepnote_cell_type":"code"},"source":"# Example\nnT = 50\nrT = 21\nerrorT = rT / nT\nprint(\"Estimation of the error on the training set\",errorT)\nprint(\"Mean and variance of the number of errors\",scipy.stats.binom.stats(nT, errorT))","block_group":"64075d9d55f64022b0b5164127002e10","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"f230acf084c34ada823222ea1ab017c8","deepnote_cell_type":"markdown"},"source":"Using `scipy`, plotting the probability mass function for the number of errors for a hypothesis with the error rate `errorT` is easy.","block_group":"11846d457d874dc7b9d7bfc7f51f5d0b"},{"cell_type":"code","metadata":{"cell_id":"826d947f09eb4735981e2c97c1463578","deepnote_cell_type":"code"},"source":"from scipy.stats import binom\n\nrv = binom(nT, errorT)                  # random variable from the binomial distribution \n                                        # with nT experiments with the probablity errorT of success \nx = np.arange(nT+1)\n\nplt.vlines(x, 0, binom.pmf(x, nT, errorT))","block_group":"0f1b7c324a744dd38973d3eb87290b9b","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"9f7ba17d24924bbeaf65d38cf207c84b","deepnote_cell_type":"markdown"},"source":"Cumulative distribution function. ","block_group":"e9b539ac147144ecb93d5044def1504e"},{"cell_type":"code","metadata":{"cell_id":"edcdb8434b4841148fa4292f827294b7","deepnote_cell_type":"code"},"source":"x1 = x + 0.99\nxx = np.append(x,x1)\nxx.sort()\nplt.plot(xx, binom.cdf(xx, nT, errorT))","block_group":"fd0983972908466e918b53c4ddab782f","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"242800abd79c40d8b958aeb07c4b09f1","deepnote_cell_type":"markdown"},"source":"Now, we can compute the confidence interval - the\ninterval to which belongs the actual error rate of the hypothesis $h$ on\nthe whole set $X$ with a prescribed probability $\\alpha=0.95$. ","block_group":"3146e10a61894ebd840110d15c660aed"},{"cell_type":"code","metadata":{"cell_id":"5efca113d005426699c6bffb0fce27c0","deepnote_cell_type":"code"},"source":"alpha = 0.95\nk = scipy.stats.binom.ppf(alpha, nT, errorT)   # Percent point function (inverse of cdf â€” percentiles).\nprint(f\"With the confidence alpha={alpha}, the hypothesis h makes at most k={k} errors\")","block_group":"d6140368b5f44cab8c0a933ac1623501","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"ae5140b1e6b54ebba8a084e8a0656a12","deepnote_cell_type":"markdown"},"source":"i.e., errors on a test set of size $n_T$.\nTherefore, the error rate of hypothesis $h$ on the whole $X$ belongs to\nthe interval $<0,\\texttt{k}/n_T>$ with the confidence $\\alpha$.","block_group":"9212d4789ce24862aa9dcbe516d6ce62"},{"cell_type":"markdown","metadata":{"cell_id":"a1c6e12d2fc24821befa68573232728a","deepnote_cell_type":"markdown"},"source":"For a sufficiently large $n_T$ (e.g., $n_T \\ge 30$, or $n_T \\cdot\n{\\sf Error}_T(h)\\cdot (1 - {\\sf Error}_T(h)) \\ge 5$, respectively), the\nbinomial distribution can be approximated by the normal distribution\nwith mean ${\\sf Error}_T(h)$ and standard deviation $\\sigma_T(h)$.\nConsequently, the two-sided $P$%-confidence interval is given by the\nfollowing formula $${\\sf Error}_T(h)\\pm z_P \\cdot \\sigma_T\\enspace,$$\nwhere the values of $z_P$ are called quantiles and can be found in\nstatistical tables. Using `scipy.stats.norm` it is possible to compute $z_P$ directly:","block_group":"bb3a6f0d99e1410ea20478d453a018d1"},{"cell_type":"code","metadata":{"cell_id":"250fef9aaf5b469cbca4b74623a104c7","deepnote_cell_type":"code"},"source":"from scipy.stats import norm\n\na = np.array([80,90,95,98,99])\nb=(100+a)/2/100\nprint(a)\nprint(b)\nnorm.ppf(b)\n","block_group":"82ab9034f08745bd9fb33506cc441915","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"06c917a4db93400ca7183efb40f9ee24","deepnote_cell_type":"markdown"},"source":"Hence, e.g., approximately $z_{95} \\approx 1.96$ and $z_{99} \\approx 2.5758$.","block_group":"f374ad399f5249f4ac5f494d870ec17e"},{"cell_type":"markdown","metadata":{"cell_id":"b2642eb9a3c44e70b9d8cec8f2b792b2","deepnote_cell_type":"markdown"},"source":"In a single graph, plot the binomial probability distribution for $n=40$\nsamples with the probability of success $p=0.1$ (as this is a discrete\nprobability distribution, your task is to plot the distribution function\nfor arguments $0,\\dots,n$) and the normal probability distribution with\nthe same mean and standard deviation (in this case, it is a continuous\nprobability distribution, hence you should plot its continuous density\nfunction).","block_group":"dba3a695129f417f870f7fa426791cfa"},{"cell_type":"code","metadata":{"nbgrader":{"task":false,"grade":false,"locked":false,"checksum":"efc91797da7ccfbcaf51bd6c4fdbc9df","grade_id":"cell-057de577ff574a70","solution":true,"cell_type":"code","schema_version":3},"deletable":false,"cell_id":"9e7fd46681584830a698f405b70a55f4","deepnote_cell_type":"code"},"source":"# YOUR CODE HERE\nraise NotImplementedError()","block_group":"5509e2aeb11442b9bd03fe83decacb5e","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"682887db536b4650beda4dbd8a58a453","deepnote_cell_type":"markdown"},"source":"**A general guidance for deriving a confidence interval**\n\nA $N$% confidence interval for a parameter $p$ is an interval that is\nexpected with probability $N$% to contain $p$.\n\nMethod:\n\n1.  Identify the parameter $p$, which should be estimated - e.g., the\n    error of a hypothesis ${\\sf Error}_D(h)$.\n\n2.  Derive the estimate $Y$ - in our case, ${\\sf\n        Error}_T(h)$. If possible, use an unbiased estimate with minimal\n    variance.\n\n3.  Determine the probability distribution $D_Y$ for $Y$, including its\n    mean and standard deviation.\n\n4.  Establish $N$% confidence interval - i.e., find the limits $L$ and\n    $U$ such that $N$% of samples selected according to the probability\n    distribution $D_Y$ are between $L$ and $U$.","block_group":"5ca74775610044a0848735688be36338"},{"cell_type":"markdown","metadata":{"cell_id":"33c877477d3c4ec7bf03d7a265aad3d9","deepnote_cell_type":"markdown"},"source":"# Comparing Learning Algorithms\n\nLearning algorithms can be compared using methods for comparing\nstatistical hypotheses, but better results can be obtained from pair\ntests or $k$-fold cross-validation.","block_group":"4b780987a86b43deaaf9aa3af06d0d35"},{"cell_type":"markdown","metadata":{"cell_id":"113d91c241c5466aa916888051739639","deepnote_cell_type":"markdown"},"source":"## Difference in Error of Two Hypotheses\n\nSuppose that a hypothesis $h_1$ is tested on a set $T_1$ od size $n_1$ and a hypothesis\n$h_2$ is tested on a set $T_2$ of size $n_2$. We want to estimate the\ndifference $d={\\sf Error}_D(h_1)-{\\sf Error}_D(h_2)$ between their\nerrors when the samples were drawn from the same underlying probability\ndistribution $D$. Similarly to the above\nsection, we\nassume that the range of the target function is discrete and the error\nof the hypothesis can be computed as the fraction of incorrectly\nclassified samples from the tested samples. An unbiased estimator for\nthe difference of errors is\n$$\\widehat{d}={\\sf Error}_{T_1}(h_1)-{\\sf Error}_{T_2}(h_2)\\enspace.$$\nThis method has a disadvantage in that the hypotheses have not only\ndifferent errors but also variances. Hence, the difference in the errors\ncan be approximated by a normal distribution with the mean $\\widehat{d}$\nand variance\n$$\\sigma^2_{\\widehat{d}} =\\frac{{\\sf Error}_{T_1}(h_1) \\cdot (1-{\\sf Error}_{T_1}(h_1))}{n_1} + \\frac{{\\sf Error}_{T_2}(h_2) \\cdot\n(1-{\\sf Error}_{T_2}(h_2))}{n_2}\\enspace.$$ Therefore $N$% confidence\ninterval for the estimator $\\widehat{d}$ is:\n$$\\widehat{d} \\pm z_N \\sqrt{\\sigma^2_{\\widehat{d}}}\\enspace.$$","block_group":"70259d785415465ba42565c460a481b6"},{"cell_type":"markdown","metadata":{"cell_id":"8c3340bff7dc4c8c9b063ab679e559f0","deepnote_cell_type":"markdown"},"source":"## Paired Tests\n\nWe are interested in comparing not just two hypotheses but two learning\n*algorithms*. We can decrease the variance of the difference in their\nerrors by training both algorithms on the same training set and testing\nthem on the same test set. The obtained confidence intervals are\nnarrower because the difference in the performance of the learning\nalgorithms is then caused by the algorithms themselves, not by different\ninput data.\n\nLet $L_A$ and $L_B$ be two learning algorithms learning the same target\nfunction $f$. For the comparison, we should compare $L_A$ and $L_B$ by\nlearning on all subsets of $X$ of size $n$ selected according to the\nsame probabilistic distribution $D$. Then, the expected value of the\ndifference in error rates for the learning algorithms $L_A$ and $L_B$ is\n$$E_{T \\subset D}[{\\sf Error}_D(L_A(T)) - {\\sf\nError}_D(L_B(T))]\\enspace,$$ where $L_{\\alpha}(T)$ denotes the\nhypothesis output by the learning algorithm $L_{\\alpha}$ after learning\nfrom the training set $T$ ($\\alpha \\in \\{A,B\\}$). The expected value is\ncomputed on subsets (of size $n$) of $X$ selected according to the\nprobability distribution $D$.\n\nWhen comparing learning algorithms in practice, we have only a limited\nsample $D_0$. Therefore, we split $D_0$ randomly into a training set\n$S_0$ and a test set $T_0$, which are disjoint. The training samples are\nused to train both $L_A$ and $L_B$. The test data is used for comparing\nthe accuracy of the trained hypotheses - the obtained error rates are\nsubtracted: $$\n{\\sf Error}_{T_0}(L_A(S_0))-{\\sf Error}_{T_0}(L_B(S_0))\\enspace.$$ Hence, \nthe difference in error rates for $L_A$ and $L_B$ is measured on a\nsingle training set $S_0$ and not as the expected value of the\ndifference on all samples $S$ that might be drawn from the distribution\n$D$. ","block_group":"9a53ec52fe7d454a9872e8678c9fb1b3"},{"cell_type":"markdown","metadata":{"cell_id":"b45b570706f741fe8efeecb9972256c2","deepnote_cell_type":"markdown"},"source":"## $k$-Fold Cross-Validation\n\nIf we have enough data, we can use them better. One way to improve \nthe estimator given by the above formula is to\npartition the data $D_0$ into disjoint training and test sets and to\ntake the mean of the test errors. The procedure is as follows:\n\n1.  Partition the data $D_0$ into $k$ pairwise disjoint sets $T_1,$\n    $T_2,\\dots,T_k$ of equal size. **The size of $T_i$ should be at\n    least 30!**\n\n2.  For $i=1,\\dots,k$ do:\n    * take $T_i$ for the test set and the remaining data for the training\n      set $S_i$\n    \n    * $S_i$ := $D_0 \\setminus T_i$\n    \n    * $h_A := L_A(S_i)$\n    \n    * $h_B := L_B(S_i)$\n    \n    * $\\delta_i := {\\sf Error}_{T_i}(h_A)-{\\sf Error}_{T_i}(h_B)$\n   \n\n3.  The resulting value of the difference of errors of $L_A$ a $L_B$ is\n    $$\\overline{\\delta} = \\frac{1}{k} \\sum_{i=1}^k\n        \\delta_i\\enspace.$$ The approximate $N$% confidence interval of the\n    real difference of errors is\n    $$\\left<\\overline{\\delta}-t_{N,k-1}\\cdot \\frac{\\sigma_{\\overline{\\delta}}}{\\sqrt{k}},\\;\\;\\overline{\\delta}+t_{N,k-1}\\cdot \\frac{\\sigma_{\\overline{\\delta}}}{\\sqrt{k}}\\right>,$$\n    where $\\sigma_{\\overline{\\delta}}$ is an estimate of the standard\n    deviation\n    $$\\sigma_{\\overline{\\delta}} = \\sqrt{\\frac{1}{k-1} \\sum_{i=1}^{k} (\\delta_i - \\overline{\\delta})^2}$$\n    and $t_{N,k-1}$ is the $\\frac{N+100}{2}$% quantile of the Student\n    $t$-distribution with $k-1$ degrees of freedom. Using `scipy.stats.t`, we can\n    compute $t_{N,k-1}$ as it follows","block_group":"d693c74266374f6491262af2957b45dd"},{"cell_type":"code","metadata":{"cell_id":"4e86ea504d1149548d669dda84d05d13","deepnote_cell_type":"code"},"source":"from scipy.stats import t\n\nN = a\nprint(N)\nt.ppf((a+100)/200,k-1)","block_group":"aa56c00304214e6f8deb49eeea518519","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"32d70abf39204c629e7c128a67e4e5d5","deepnote_cell_type":"code"},"source":"k = 5\nfrom scipy.stats import t\n\nN = a\nprint(N)\nt.ppf((a+100)/200,k-1)","block_group":"d9e8c7786dbc4217ac68ddd775d76ddb","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=2ee9bbc5-8ba7-4beb-8b43-4ea47a301160' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3 (ipykernel)"},"language_info":{"name":"python","version":"3.9.16","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"38de7813a1b646c48a568a53e0b1b15d","deepnote_execution_queue":[]}}