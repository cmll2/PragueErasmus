{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"3eba254f6f1148f8888aee409b227d78","deepnote_cell_type":"markdown"},"source":["Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n","\n","Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"fdd71593331446a8995f3cb85e2cedbb","deepnote_cell_type":"code"},"outputs":[],"source":["NAME = \"Camille HascoÃ«t\"\n","COLLABORATORS = \"\""]},{"cell_type":"markdown","metadata":{"cell_id":"1858bb31006d4741b810db55c38eeb21","deepnote_cell_type":"markdown"},"source":["---"]},{"cell_type":"code","execution_count":1,"metadata":{"cell_id":"2ce7d6d3b49d476f930cc30b209b9ea5","deepnote_cell_type":"code"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from icecream import ic"]},{"cell_type":"markdown","metadata":{"cell_id":"a73f5291a3c5409c8612d19fc6ca7884","deepnote_cell_type":"markdown"},"source":["# Multi-Layered Neural Networks and the Backpropagation Algorithm\n","\n","For easy computing potential on a neuron, the weights of incoming\n","synapses of the neuron are stored as a row vector.\n"," \n","Let us take a neural network with the topology [2,2,1], i.e., the network\n","has 2 input neurons, 2 hidden neurons in a single hidden layer, and one\n","output neuron. Let the weights of synapses between the input and the\n","hidden layer be in the following matrix:"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"8f13a5a05932421e9037f82827e1b869","deepnote_cell_type":"code"},"outputs":[],"source":["w_i_h = np.array([[0.5, -0.5],\n","                  [1.5,  0.5]])"]},{"cell_type":"markdown","metadata":{"cell_id":"e2af9514162643f78b92269c48a57afa","deepnote_cell_type":"markdown"},"source":["`w_i_h[i,j]` is the weight of the synapse from the input `i` into the\n","hidden neuron `j`. I.e., each row of the weight matrix corresponds to\n","the weights of synapses leading **from** one neuron!\n","\n","Let the synaptic weights between the hidden and the output layer\n","be in the matrix:"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"84649dafe3744c92a346c89441c8e5ee","deepnote_cell_type":"code"},"outputs":[],"source":["w_h_o = np.array([[2.0], [-1.0]])"]},{"cell_type":"markdown","metadata":{"cell_id":"ebf0b01162c8436ba94783721930cbca","deepnote_cell_type":"markdown"},"source":["`w_h_o[i,0]` is the weight of the connection from the hidden neuron `i` \n","to the output neuron. Thresholds of the hidden neurons are in the vector:"]},{"cell_type":"code","execution_count":4,"metadata":{"cell_id":"e2c6b1fc8fd540ddb0b41daa36cfad74","deepnote_cell_type":"code"},"outputs":[],"source":["b_h = np.array([0, 0.5])"]},{"cell_type":"markdown","metadata":{"cell_id":"983ad7902c2246178ef304b3f8e05b5f","deepnote_cell_type":"markdown"},"source":["and the threshold of the outout neuron is:"]},{"cell_type":"code","execution_count":5,"metadata":{"cell_id":"2508f942e4de4356b3acc040fdb07792","deepnote_cell_type":"code"},"outputs":[],"source":["b_o = np.array([-0.5])"]},{"cell_type":"markdown","metadata":{"cell_id":"1f2c40fb6de6481780839f6c9dfab3a8","deepnote_cell_type":"markdown"},"source":["Hence the weights from the input layer into the hidden layer with added \n","virtual neuron with fixed output 1 (for representing thresholds) are:"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"04010c69c5344289b6d4e7658071bc01","deepnote_cell_type":"code"},"outputs":[{"data":{"text/plain":["array([[ 0.5, -0.5],\n","       [ 1.5,  0.5],\n","       [ 0. ,  0.5]])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# note that r_ is not a method of numpy array!\n","w_i_hb = np.r_[w_i_h, b_h.reshape(1,-1)]\n","w_i_hb"]},{"cell_type":"markdown","metadata":{"cell_id":"b411902c675f48508a7743a645eee864","deepnote_cell_type":"markdown"},"source":["The weights from the hidden layer into the output layer\n","with added virtual neuron with output 1 are:"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"50dff3dda29a49c39a346729e71aa9ef","deepnote_cell_type":"code"},"outputs":[{"data":{"text/plain":["array([[ 2. ],\n","       [-1. ],\n","       [-0.5]])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["w_h_ob = np.r_[w_h_o, b_o.reshape(1,-1)]\n","w_h_ob"]},{"cell_type":"markdown","metadata":{"cell_id":"d5504190f54b40cba2a4128b2f37e13b","deepnote_cell_type":"markdown"},"source":["A sigmoidal transfer function $$logsig(x) = \\frac{1}{1 + e^{-\\lambda x}}$$ can be implemented as"]},{"cell_type":"code","execution_count":8,"metadata":{"cell_id":"5ae01ebd933a4bb78db9e0202917c675","deepnote_cell_type":"code"},"outputs":[],"source":["def sigmoid(x, lam=1.0):\n","    # sigmoid transfer function\n","    #     sigmoid(x) = 1/(1 + exp{-lam * x)\n","    return 1 / (1 + np.exp(-lam * x))"]},{"cell_type":"code","execution_count":9,"metadata":{"cell_id":"6da6bfe975834e49b35d5573bafbe381","deepnote_cell_type":"code"},"outputs":[{"data":{"text/plain":["0.9525741268224334"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["1/(1+np.exp(-3))"]},{"cell_type":"code","execution_count":10,"metadata":{"cell_id":"23711232d21f4ef6bbbc3aaa8e2965e1","deepnote_cell_type":"code"},"outputs":[{"data":{"text/plain":["0.9525741268224334"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["sigmoid(3)"]},{"cell_type":"markdown","metadata":{"cell_id":"6ffb1b47bfb745deb76c62a404da910e","deepnote_cell_type":"markdown"},"source":["This is the sigmoid function with the slope $\\lambda$. The default value for the slope is $\\lambda = 1$."]},{"cell_type":"markdown","metadata":{"cell_id":"f6bacd9134d640ffac5168710a5f6185","deepnote_cell_type":"markdown"},"source":["## Tasks:\n","\n","* *Let $\\lambda=1$. Compute the output of the network for the input patterns `p1` and `p2`.*"]},{"cell_type":"code","execution_count":11,"metadata":{"cell_id":"cf390a04d55f46bda9ffbd1518d0a434","deepnote_cell_type":"code"},"outputs":[],"source":["lamb = 1.0\n","p1 = np.array([-1, 1])\n","p2 = np.array([ 1,-1])"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["def neural_network(x, w_i_hb, w_h_ob, lamb=1.0):\n","    if len(x) == w_i_hb.shape[0] - 1:\n","        x = np.append(x, 1)\n","    x_h = sigmoid(np.append(np.dot(x, w_i_hb), 1))\n","    x_o = sigmoid(np.dot(x_h, w_h_ob))\n","    return x_o"]},{"cell_type":"code","execution_count":29,"metadata":{"cell_id":"b5ea2bf6f85442239489d93b92e84cec","deepnote_cell_type":"code","deletable":false,"nbgrader":{"cell_type":"code","checksum":"9fd09b7387457edf2734948a48a6ead5","grade":false,"grade_id":"cell-8e13b5fce042ae6d","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 0.5 -0.5]\n"," [ 1.5  0.5]\n"," [ 0.   0.5]]\n","p1\n","[0.56930433]\n","p2\n","[0.44888244]\n"]}],"source":["print(w_i_hb)\n","print(\"p1\")\n","print(neural_network(p1, w_i_hb, w_h_ob, lamb))\n","print(\"p2\")\n","print(neural_network(p2, w_i_hb, w_h_ob, lamb))\n"]},{"cell_type":"markdown","metadata":{"cell_id":"f9326eb7371844988ae83fe205b189f1","deepnote_cell_type":"markdown"},"source":["* *Compute the utput of the network for the whole training set `X` consisting of the patterns `p1` and `p2`.*"]},{"cell_type":"code","execution_count":33,"metadata":{"cell_id":"90c5adcf52b04b54817f3bad4e44385b","deepnote_cell_type":"code","deletable":false,"nbgrader":{"cell_type":"code","checksum":"1efef519abbb01edb6d0e46f2cbdeb70","grade":false,"grade_id":"cell-bb2e95cf171d5dda","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-1.  1.  1.]\n"," [ 1. -1.  1.]]\n","[0.56930433 0.44888244]\n"]}],"source":["X = np.vstack((p1,p2))\n","print(np.c_[X, np.ones(X.shape[0])])\n","y = []\n","for x in X:\n","    y.append(neural_network(x, w_i_hb, w_h_ob, lamb))\n","y = np.array(y).flatten()\n","print(y)\n","    "]},{"cell_type":"markdown","metadata":{"cell_id":"8f349b7ce6794896ad62715e0a936f52","deepnote_cell_type":"markdown"},"source":["The input pattern  `p1` is a training vector with the desired\n","output 0.9 and the input pattern `p2` is also a trianing pattern with the desired output 0.8. Hence the desired outputs we can store in an array, where row `d[i]` are the desired output for the pattern `X[i]`."]},{"cell_type":"code","execution_count":34,"metadata":{"cell_id":"bc93b1d0b4cf4110a1e7587c12bd7d20","deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":["d\n"," [[0.9]\n"," [0.8]]\n"]}],"source":["d = np.array([[0.9],[0.8]])\n","print(\"d\\n\",d)"]},{"cell_type":"markdown","metadata":{"cell_id":"94f1ddbf509a4ff7b7d617a55b041935","deepnote_cell_type":"markdown"},"source":["* *What is the error of the network on each of the patterns `p1` and `p2`?*"]},{"cell_type":"code","execution_count":36,"metadata":{"cell_id":"bc111e6662e44736b39619e9d921e90e","deepnote_cell_type":"code","deletable":false,"nbgrader":{"cell_type":"code","checksum":"07d6fe118e151deb2c6810111448f898","grade":false,"grade_id":"cell-1f0991361744566c","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[{"name":"stdout","output_type":"stream","text":["error\n"," 0.24468535739351713\n"]}],"source":["def error(y, d):\n","    return np.sum((y - d)**2) / 2\n","print(\"error\\n\",error(y, d))"]},{"cell_type":"markdown","metadata":{"cell_id":"f2858fe36071496f9c2a3bffdbaa6ef1","deepnote_cell_type":"markdown"},"source":["* *What is the mean squared error (MSE) of the network on the whole training set?*"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"a2de3ad9b29b4218a5f9f26728c12973","deepnote_cell_type":"code","deletable":false,"nbgrader":{"cell_type":"code","checksum":"ec34642b43c47a1daa3c6fd8bec1b2ff","grade":false,"grade_id":"cell-65f7a5b84e447a29","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# YOUR CODE HERE\n","raise NotImplementedError()"]},{"cell_type":"markdown","metadata":{"cell_id":"630de55cd6864822a6d72bbb4d94f77a","deepnote_cell_type":"markdown"},"source":["* *How will change the weights of the network after one step of the\n","  backpropagation learning algorithm (without momentum) with the training pattern `p1`\n","  with the learning rate $\\alpha = 0.2$?*"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"4fc7fd60cb4f4f0390ff8c97215b6e12","deepnote_cell_type":"code"},"outputs":[],"source":["alpha = 0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"d2cd5e554190495491a25fcce755a203","deepnote_cell_type":"code","deletable":false,"nbgrader":{"cell_type":"code","checksum":"d06e7b05a395660e6fcdac7d2c27a39d","grade":false,"grade_id":"cell-8e8822205f851ffa","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["pat = 0\n","delta_o = ...               # delta terms at the output layer\n","delta_h = ...               # delta terms at the hidden layer\n","w_h_ob1 = ...               # new weights from the hidden to the output layer\n","w_i_hb1 = ...               # new weights form the input to the output layer\n","# YOUR CODE HERE\n","raise NotImplementedError()"]},{"cell_type":"markdown","metadata":{"cell_id":"65c61227b694473c88479f87e6b17852","deepnote_cell_type":"markdown"},"source":["** for `p1`**"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"edc2acbd84ef4a1c99ec2f3144f263a0","deepnote_cell_type":"code","deletable":false,"nbgrader":{"cell_type":"code","checksum":"724349f26c442c92da5802e932017a73","grade":false,"grade_id":"cell-e03e91dbe4b01446","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# YOUR CODE HERE\n","raise NotImplementedError()"]},{"cell_type":"markdown","metadata":{"cell_id":"73d8dd4da8274e56ad409e869777f17c","deepnote_cell_type":"markdown"},"source":["   \n","* How will change the output of the network for input `p1` after the first \n","  iteration of the backpropagation algorithm?*"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"928e5cd97d3f4030a1946a6c8343589c","deepnote_cell_type":"code","deletable":false,"nbgrader":{"cell_type":"code","checksum":"cf2354dbeb9d86ad50e57152cf5116a4","grade":false,"grade_id":"cell-10833e3745521393","locked":false,"schema_version":3,"solution":true,"task":false}},"outputs":[],"source":["# YOUR CODE HERE\n","raise NotImplementedError()"]},{"cell_type":"markdown","metadata":{"cell_id":"8a8fa1b10fda4bb09291f9d6f9f57013","deepnote_cell_type":"markdown"},"source":["* *Estimate the number of iterations over the pattern `p1` necessary to obtain an error \"close\" to 0*"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"34b49b4be5da4f2aa05a810f2f910829","deepnote_cell_type":"code"},"outputs":[],"source":["alpha = 0.2\n","lam = 1.0\n","\n"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=936847e6-8769-4eca-a578-6e1b2af8cac4' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"0a4db753a035421faec49dbe86feda74","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
